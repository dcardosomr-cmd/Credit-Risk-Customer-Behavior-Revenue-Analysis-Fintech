{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7ea99e-b979-45b6-bf86-077b0dad3938",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/credit_applications.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ══════════════════════════════════════════════════════════════\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. LOAD DATA\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ══════════════════════════════════════════════════════════════\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m ca = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/credit_applications.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m tx = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/transactions_fintech.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m ua = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/user_activity_retention.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/credit_applications.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 1. LOAD DATA\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "ca = pd.read_csv(\"data/credit_applications.csv\")\n",
    "tx = pd.read_csv(\"data/transactions_fintech.csv\")\n",
    "ua = pd.read_csv(\"data/user_activity_retention.csv\")\n",
    "uc = pd.read_csv(\"data/users_cohort.csv\")\n",
    "\n",
    "# Parse dates\n",
    "ca[\"application_date\"] = pd.to_datetime(ca[\"application_date\"])\n",
    "ca[\"approval_date\"] = pd.to_datetime(ca[\"approval_date\"], errors=\"coerce\")\n",
    "tx[\"timestamp\"] = pd.to_datetime(tx[\"timestamp\"])\n",
    "ua[\"activity_date\"] = pd.to_datetime(ua[\"activity_date\"])\n",
    "uc[\"signup_date\"] = pd.to_datetime(uc[\"signup_date\"])\n",
    "\n",
    "# Filter to complete years 2024–2025\n",
    "ca_full = ca[ca[\"application_date\"].dt.year.isin([2024, 2025])].copy()\n",
    "tx_full = tx[tx[\"timestamp\"].dt.year.isin([2024, 2025])].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Credit applications (2024-2025): {len(ca_full):,}\")\n",
    "print(f\"Credit applications (all):       {len(ca):,}\")\n",
    "print(f\"Transactions (2024-2025):        {len(tx_full):,}\")\n",
    "print(f\"User activity records:           {len(ua):,}\")\n",
    "print(f\"User cohort records:             {len(uc):,}\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 2. EXECUTIVE SUMMARY METRICS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Total applications:       {len(ca_full):,}\")\n",
    "print(f\"Unique users (credit):    {ca_full['user_id'].nunique():,}\")\n",
    "print(f\"Total requested amount:   ${ca_full['requested_amount'].sum():,.0f}\")\n",
    "print(f\"Avg requested amount:     ${ca_full['requested_amount'].mean():,.0f}\")\n",
    "print(f\"Avg annual income:        ${ca_full['annual_income'].mean():,.0f}\")\n",
    "print(f\"Overall approval rate:    {ca_full['is_approved'].mean() * 100:.1f}%\")\n",
    "\n",
    "approval_days = (ca_full[\"approval_date\"] - ca_full[\"application_date\"]).dt.days\n",
    "print(f\"Avg approval time:        {approval_days.mean():.1f} days\")\n",
    "\n",
    "approved = ca_full[ca_full[\"is_approved\"] == True]\n",
    "print(f\"Default rate (approved):  {approved['default_flag'].mean() * 100:.2f}%\")\n",
    "print(f\"Total defaults:           {approved['default_flag'].sum():,.0f}\")\n",
    "\n",
    "print(f\"\\nTotal transactions:       {len(tx_full):,}\")\n",
    "print(f\"Total txn amount:         ${tx_full['amount'].sum():,.0f}\")\n",
    "print(f\"Fraud count:              {tx_full['is_fraud'].sum():,}\")\n",
    "print(f\"Fraud rate:               {tx_full['is_fraud'].mean() * 100:.2f}%\")\n",
    "print(f\"Completed txns:           {(tx_full['status'] == 'completed').sum():,}\")\n",
    "print(f\"Failed txns:              {(tx_full['status'] == 'failed').sum():,}\")\n",
    "\n",
    "refund_txns = tx_full[tx_full[\"transaction_type\"] == \"refund\"]\n",
    "print(f\"\\nRefund-type txns:         {len(refund_txns):,}\")\n",
    "print(f\"Refund-type amount:       ${refund_txns['amount'].sum():,.0f}\")\n",
    "print(f\"Refund % of total count:  {len(refund_txns) / len(tx_full) * 100:.1f}%\")\n",
    "print(f\"  NOTE: These are transaction_type='refund', NOT status='refunded'\")\n",
    "print(f\"  Actual refunded status count: {(tx_full['status'] == 'refunded').sum()}\")\n",
    "\n",
    "print(f\"\\nTotal users in cohort:    {len(uc):,}\")\n",
    "print(f\"Avg LTV:                  ${uc['total_lifetime_value'].mean():,.2f}\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 3. YEAR-OVER-YEAR COMPARISON\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"YEAR-OVER-YEAR COMPARISON (2024 vs 2025)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ca_full[\"year\"] = ca_full[\"application_date\"].dt.year\n",
    "yoy = ca_full.groupby(\"year\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_income=(\"annual_income\", \"mean\"),\n",
    ").round(2)\n",
    "\n",
    "print(yoy.to_string())\n",
    "print(f\"\\nYoY apps change:      {(yoy.loc[2025, 'apps'] / yoy.loc[2024, 'apps'] - 1) * 100:.2f}%\")\n",
    "print(f\"YoY total_req change: {(yoy.loc[2025, 'total_req'] / yoy.loc[2024, 'total_req'] - 1) * 100:.2f}%\")\n",
    "print(f\"YoY approval change:  {yoy.loc[2025, 'approval_rate'] - yoy.loc[2024, 'approval_rate']:.2f}pp\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 4. QUARTERLY TRENDS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"QUARTERLY APPLICATION TRENDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ca_full[\"quarter\"] = ca_full[\"application_date\"].dt.to_period(\"Q\")\n",
    "q = ca_full.groupby(\"quarter\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_income=(\"annual_income\", \"mean\"),\n",
    ").round(2)\n",
    "q[\"qoq_apps_pct\"] = (q[\"apps\"].pct_change() * 100).round(2)\n",
    "\n",
    "print(q.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 5. MONTHLY TRENDS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MONTHLY APPLICATION TRENDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ca_full[\"month\"] = ca_full[\"application_date\"].dt.to_period(\"M\")\n",
    "m = ca_full.groupby(\"month\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    ").round(2)\n",
    "\n",
    "print(m.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 6. CREDIT SCORE BAND ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREDIT SCORE BAND ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "bins = [0, 600, 700, 763, 800, 850, 901]\n",
    "labels = [\"<600\", \"600-699\", \"700-762\", \"763-799\", \"800-849\", \"850+\"]\n",
    "ca_full[\"score_band\"] = pd.cut(ca_full[\"credit_score\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "sb = ca_full.groupby(\"score_band\", observed=True).agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    ").round(2)\n",
    "sb[\"pct_of_total\"] = (sb[\"apps\"] / sb[\"apps\"].sum() * 100).round(1)\n",
    "\n",
    "# Default rate by score band\n",
    "approved_bands = ca_full[ca_full[\"is_approved\"] == True].copy()\n",
    "approved_bands[\"score_band\"] = pd.cut(\n",
    "    approved_bands[\"credit_score\"], bins=bins, labels=labels, right=False\n",
    ")\n",
    "dr = approved_bands.groupby(\"score_band\", observed=True).agg(\n",
    "    defaults=(\"default_flag\", \"sum\"),\n",
    "    approved_count=(\"application_id\", \"count\"),\n",
    ")\n",
    "dr[\"default_rate\"] = (dr[\"defaults\"] / dr[\"approved_count\"] * 100).round(2)\n",
    "sb = sb.join(dr[[\"default_rate\"]])\n",
    "\n",
    "print(sb.to_string())\n",
    "print(\"\\n>>> NOTE: Default rate is ~5% across ALL score bands — model may lack\")\n",
    "print(\"    discriminatory power for predicting defaults.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 7. LOAN PURPOSE ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOAN PURPOSE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lp = ca_full.groupby(\"loan_purpose\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    ").round(2)\n",
    "lp[\"pct_of_total\"] = (lp[\"apps\"] / lp[\"apps\"].sum() * 100).round(1)\n",
    "\n",
    "# Default rate by loan purpose\n",
    "dr_lp = approved.groupby(\"loan_purpose\").agg(\n",
    "    defaults=(\"default_flag\", \"sum\"),\n",
    "    approved_count=(\"application_id\", \"count\"),\n",
    ")\n",
    "dr_lp[\"default_rate\"] = (dr_lp[\"defaults\"] / dr_lp[\"approved_count\"] * 100).round(2)\n",
    "lp = lp.join(dr_lp[[\"default_rate\"]])\n",
    "\n",
    "print(lp.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 8. AGE GROUP ANALYSIS (merged with cohort)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AGE GROUP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "merged = ca_full.merge(\n",
    "    uc[[\"user_id\", \"age_group\", \"account_type\", \"signup_channel\", \"country\"]],\n",
    "    on=\"user_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "ag = merged.groupby(\"age_group\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_income=(\"annual_income\", \"mean\"),\n",
    "    total_income=(\"annual_income\", \"sum\"),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    ").round(2)\n",
    "ag[\"pct_of_total\"] = (ag[\"apps\"] / ag[\"apps\"].sum() * 100).round(1)\n",
    "\n",
    "print(ag.to_string())\n",
    "\n",
    "# LTV by age group\n",
    "print(\"\\nLTV by age group:\")\n",
    "ag_ltv = uc.groupby(\"age_group\")[\"total_lifetime_value\"].agg([\"mean\", \"sum\", \"count\"]).round(2)\n",
    "ag_ltv.columns = [\"avg_ltv\", \"total_ltv\", \"users\"]\n",
    "print(ag_ltv.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 9. ACCOUNT TYPE ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACCOUNT TYPE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "at = merged.groupby(\"account_type\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    "    total_req=(\"requested_amount\", \"sum\"),\n",
    ").round(2)\n",
    "at[\"pct_of_total\"] = (at[\"apps\"] / at[\"apps\"].sum() * 100).round(1)\n",
    "\n",
    "print(\"Applications by account type:\")\n",
    "print(at.to_string())\n",
    "\n",
    "print(\"\\nLTV by account type:\")\n",
    "ltv_at = uc.groupby(\"account_type\")[\"total_lifetime_value\"].agg([\"mean\", \"sum\", \"count\"]).round(2)\n",
    "ltv_at.columns = [\"avg_ltv\", \"total_ltv\", \"users\"]\n",
    "print(ltv_at.to_string())\n",
    "print(\"\\n>>> NOTE: LTV is virtually identical across all account types (~$2,500).\")\n",
    "print(\"    Premium/enterprise tiers do not produce higher lifetime value.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 10. EMPLOYMENT STATUS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EMPLOYMENT STATUS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "es = ca_full.groupby(\"employment_status\").agg(\n",
    "    apps=(\"application_id\", \"count\"),\n",
    "    approval_rate=(\"is_approved\", lambda x: x.mean() * 100),\n",
    "    avg_income=(\"annual_income\", \"mean\"),\n",
    "    avg_req=(\"requested_amount\", \"mean\"),\n",
    ").round(2)\n",
    "es[\"pct_of_total\"] = (es[\"apps\"] / es[\"apps\"].sum() * 100).round(1)\n",
    "\n",
    "print(es.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 11. TRANSACTION ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSACTION TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tt = tx_full.groupby(\"transaction_type\").agg(\n",
    "    count=(\"transaction_id\", \"count\"),\n",
    "    amount=(\"amount\", \"sum\"),\n",
    ").round(2)\n",
    "tt[\"pct_count\"] = (tt[\"count\"] / tt[\"count\"].sum() * 100).round(1)\n",
    "tt[\"pct_amount\"] = (tt[\"amount\"] / tt[\"amount\"].sum() * 100).round(1)\n",
    "\n",
    "print(tt.to_string())\n",
    "\n",
    "print(\"\\nTransaction status distribution:\")\n",
    "print(tx_full[\"status\"].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n>>> IMPORTANT: 'refund' is a transaction_type, not a status.\")\n",
    "print(f\"    There are ZERO records with status='refunded'.\")\n",
    "print(f\"    The dashboard's '20% refund rate' = proportion of refund-type transactions.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 12. TRANSACTIONS BY COUNTRY\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSACTIONS BY COUNTRY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tc = tx_full.groupby(\"country\").agg(\n",
    "    count=(\"transaction_id\", \"count\"),\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    fraud=(\"is_fraud\", \"sum\"),\n",
    ").round(2)\n",
    "tc[\"pct_count\"] = (tc[\"count\"] / tc[\"count\"].sum() * 100).round(1)\n",
    "tc[\"fraud_rate\"] = (tc[\"fraud\"] / tc[\"count\"] * 100).round(2)\n",
    "tc[\"avg_txn\"] = (tc[\"amount\"] / tc[\"count\"]).round(2)\n",
    "\n",
    "print(tc.sort_values(\"amount\", ascending=False).to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 13. TRANSACTIONS BY MERCHANT CATEGORY\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSACTIONS BY MERCHANT CATEGORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mc = tx_full.groupby(\"merchant_category\").agg(\n",
    "    count=(\"transaction_id\", \"count\"),\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    fraud=(\"is_fraud\", \"sum\"),\n",
    ").round(2)\n",
    "mc[\"pct_amount\"] = (mc[\"amount\"] / mc[\"amount\"].sum() * 100).round(1)\n",
    "mc[\"fraud_rate\"] = (mc[\"fraud\"] / mc[\"count\"] * 100).round(2)\n",
    "\n",
    "print(mc.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 14. TRANSACTIONS BY PAYMENT METHOD\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSACTIONS BY PAYMENT METHOD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pm = tx_full.groupby(\"payment_method\").agg(\n",
    "    count=(\"transaction_id\", \"count\"),\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    fraud=(\"is_fraud\", \"sum\"),\n",
    ").round(2)\n",
    "pm[\"fraud_rate\"] = (pm[\"fraud\"] / pm[\"count\"] * 100).round(2)\n",
    "\n",
    "print(pm.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 15. QUARTERLY TRANSACTION TRENDS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"QUARTERLY TRANSACTION TRENDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tx_full[\"quarter\"] = tx_full[\"timestamp\"].dt.to_period(\"Q\")\n",
    "tq = tx_full.groupby(\"quarter\").agg(\n",
    "    count=(\"transaction_id\", \"count\"),\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    fraud=(\"is_fraud\", \"sum\"),\n",
    "    completed=(\"status\", lambda x: (x == \"completed\").sum()),\n",
    "    failed=(\"status\", lambda x: (x == \"failed\").sum()),\n",
    ").round(2)\n",
    "tq[\"fraud_rate\"] = (tq[\"fraud\"] / tq[\"count\"] * 100).round(2)\n",
    "\n",
    "print(tq.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 16. COMPLETED FRAUD INVESTIGATION\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPLETED FRAUD TRANSACTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "completed_fraud = tx_full[(tx_full[\"status\"] == \"completed\") & (tx_full[\"is_fraud\"] == True)]\n",
    "print(f\"Count:  {len(completed_fraud):,}\")\n",
    "print(f\"Amount: ${completed_fraud['amount'].sum():,.0f}\")\n",
    "print(f\"\\nThese transactions passed through as completed despite being flagged as fraud.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 17. USER ACTIVITY — DEVICE ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"USER ACTIVITY BY DEVICE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dev = ua.groupby(\"device_type\").agg(\n",
    "    sessions=(\"activity_id\", \"count\"),\n",
    "    total_duration=(\"session_duration_minutes\", \"sum\"),\n",
    "    avg_duration=(\"session_duration_minutes\", \"mean\"),\n",
    "    avg_pages=(\"pages_viewed\", \"mean\"),\n",
    "    avg_actions=(\"actions_taken\", \"mean\"),\n",
    ").round(2)\n",
    "dev[\"pct_sessions\"] = (dev[\"sessions\"] / dev[\"sessions\"].sum() * 100).round(1)\n",
    "\n",
    "print(dev.to_string())\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 18. USER ACTIVITY — DAY OF WEEK\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"USER ACTIVITY BY DAY OF WEEK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ua[\"dow\"] = ua[\"activity_date\"].dt.day_name()\n",
    "order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "dow = (\n",
    "    ua.groupby(\"dow\")\n",
    "    .agg(\n",
    "        sessions=(\"activity_id\", \"count\"),\n",
    "        avg_duration=(\"session_duration_minutes\", \"mean\"),\n",
    "        total_duration=(\"session_duration_minutes\", \"sum\"),\n",
    "        avg_pages=(\"pages_viewed\", \"mean\"),\n",
    "        avg_actions=(\"actions_taken\", \"mean\"),\n",
    "    )\n",
    "    .round(2)\n",
    "    .reindex(order)\n",
    ")\n",
    "\n",
    "print(dow.to_string())\n",
    "print(\"\\n>>> NOTE: Sessions are evenly distributed across all days (~42.5K–43.3K).\")\n",
    "print(\"    There is no meaningful Sunday/Monday peak.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 19. CORRELATION ANALYSIS\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "corr_pages_actions = ua[\"pages_viewed\"].corr(ua[\"actions_taken\"])\n",
    "corr_duration_actions = ua[\"session_duration_minutes\"].corr(ua[\"actions_taken\"])\n",
    "corr_duration_pages = ua[\"session_duration_minutes\"].corr(ua[\"pages_viewed\"])\n",
    "\n",
    "print(f\"pages_viewed vs actions_taken:        r = {corr_pages_actions:.4f}\")\n",
    "print(f\"session_duration vs actions_taken:     r = {corr_duration_actions:.4f}\")\n",
    "print(f\"session_duration vs pages_viewed:      r = {corr_duration_pages:.4f}\")\n",
    "print(\"\\n>>> NOTE: All correlations are essentially zero.\")\n",
    "print(\"    Pages viewed does NOT predict actions taken.\")\n",
    "print(\"    Session duration does NOT predict engagement.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 20. LTV ANALYSIS BY SEGMENT\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LIFETIME VALUE BY SEGMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nBy signup channel:\")\n",
    "sc = uc.groupby(\"signup_channel\").agg(\n",
    "    users=(\"user_id\", \"count\"),\n",
    "    avg_ltv=(\"total_lifetime_value\", \"mean\"),\n",
    "    total_ltv=(\"total_lifetime_value\", \"sum\"),\n",
    ").round(2)\n",
    "sc[\"pct_users\"] = (sc[\"users\"] / sc[\"users\"].sum() * 100).round(1)\n",
    "print(sc.to_string())\n",
    "\n",
    "print(\"\\nBy country:\")\n",
    "cc = uc.groupby(\"country\").agg(\n",
    "    users=(\"user_id\", \"count\"),\n",
    "    avg_ltv=(\"total_lifetime_value\", \"mean\"),\n",
    "    total_ltv=(\"total_lifetime_value\", \"sum\"),\n",
    ").round(2)\n",
    "cc[\"pct_users\"] = (cc[\"users\"] / cc[\"users\"].sum() * 100).round(1)\n",
    "print(cc.to_string())\n",
    "\n",
    "print(\"\\nBy verification status:\")\n",
    "ver = uc.groupby(\"is_verified\").agg(\n",
    "    users=(\"user_id\", \"count\"),\n",
    "    avg_ltv=(\"total_lifetime_value\", \"mean\"),\n",
    ").round(2)\n",
    "print(ver.to_string())\n",
    "print(\"\\n>>> NOTE: LTV is ~$2,501 across ALL segments. No meaningful differentiation.\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 21. CONVERSION FUNNEL (from dashboard event data)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONVERSION FUNNEL (from dashboard)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "funnel = [\n",
    "    (\"app_open\", 128000),\n",
    "    (\"view_homepage\", 108000),\n",
    "    (\"view_product\", 90000),\n",
    "    (\"add_to_cart\", 51000),\n",
    "    (\"begin_checkout\", 38000),\n",
    "    (\"add_payment_method\", 32000),\n",
    "    (\"submit_order\", 28000),\n",
    "    (\"order_confirmed\", 25000),\n",
    "]\n",
    "\n",
    "print(f\"{'Stage':<25} {'Count':>8} {'Step Conv.':>12} {'Overall':>10}\")\n",
    "print(\"-\" * 58)\n",
    "for i, (stage, count) in enumerate(funnel):\n",
    "    prev_pct = f\"{count / funnel[i - 1][1] * 100:.1f}%\" if i > 0 else \"—\"\n",
    "    top_pct = f\"{count / funnel[0][1] * 100:.1f}%\"\n",
    "    marker = \" <<< BIGGEST DROP\" if i == 3 else \"\"\n",
    "    print(f\"{stage:<25} {count:>8,} {prev_pct:>12} {top_pct:>10}{marker}\")\n",
    "\n",
    "print(\"\\n>>> NOTE: The biggest drop-off is view_product -> add_to_cart (43.3% loss).\")\n",
    "print(\"    This is the primary UX optimisation target, not checkout.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50646ad6-94a7-44d6-87a4-6c71e135d0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
